# Forecasts SARS-CoV-2

> :warning: **WARNING: This is an alpha release.** Output file format and address may change at any time

## Automated pipeline
The automated pipeline runs daily based on a scheduled jobs and triggers from upstream data ingests.
* Case counts are fetched from [external data sources](#data-sources) daily at 8 AM PST
* Raw metadata/sequences are fetched and cleaned via [nextstrain/ncov-ingest].
    * See [GISAID](https://github.com/nextstrain/ncov-ingest/blob/master/.github/workflows/fetch-and-ingest-gisaid-master.yml) and [open](https://github.com/nextstrain/ncov-ingest/blob/master/.github/workflows/fetch-and-ingest-genbank-master.yml) data workflows for their daily scheduled times
* The [nextstrain/ncov-ingest] pipelines trigger the clade counts jobs once the latest curated data has been uploaded to S3
    * The GISAID and open data ingest pipelines have different run times, so their clade counts jobs are triggered at different times.
* Clade counts jobs trigger the model runs once the counts data has been uploaded to S3
* Model results are uploaded to S3 as dated files where the date indicates the ***run*** date

### Data Sources

- Global COVID-19 case counts: [Our World in Data](https://covid.ourworldindata.org/data/owid-covid-data.csv), originally from [JHU CSSE COVID-19 Data](https://github.com/CSSEGISandData/COVID-19)
- USA state COVID-19 case counts: [United States COVID-19 Cases and Deaths by State over Time](https://data.cdc.gov/Case-Surveillance/United-States-COVID-19-Cases-and-Deaths-by-State-o/9mfq-cb36)
- SARS-CoV-2 sequences: Nextstrain-curated metadata TSVs for GISAID and GenBank produced by [nextstrain/ncov-ingest](https://github.com/nextstrain/ncov-ingest)

### Outputs

This repository produces multiple TSVs that are routinely uploaded to AWS S3 buckets.

The GISAID data is stored at `s3://nextstrain-data-private/files/workflows/forecasts-ncov/` and is not publicly available.
The open (GenBank) data is stored at `s3://nextstrain-data/files/workflows/forecasts-ncov` and is publicly available.

Within `forecasts-ncov/`, files are organized by geographic resolution and count type.
Within TSVs at the global resolution, the `location` column contains countries.
Within TSVs at the country resolution, the `location` column contains divisions (e.g. states for US).

### Summary of Available open (GenBank) files
| Geographic Resolution  | Type | Address |
| --- | --- | --- |
| Global | Cases | https://data.nextstrain.org/files/workflows/forecasts-ncov/global/cases.tsv.gz |
|        | Nextstrain clades | https://data.nextstrain.org/files/workflows/forecasts-ncov/global/nextstrain_clades.tsv.gz |
|        | MLR results | `https://data.nextstrain.org/files/workflows/forecasts-ncov/global/mlr/<YYYY-MM-DD>_results.json.zst` |
|        | Renewal results |  `https://data.nextstrain.org/files/workflows/forecasts-ncov/global/renewal/<YYYY-MM-DD>_results.json.zst` |
| USA    | Cases | https://data.nextstrain.org/files/workflows/forecasts-ncov/usa/cases.tsv.gz |
|        | Nextstrain clades | https://data.nextstrain.org/files/workflows/forecasts-ncov/usa/nextstrain_clades.tsv.gz |
|        | MLR results |  `https://data.nextstrain.org/files/workflows/forecasts-ncov/usa/mlr/<YYYY-MM-DD>_results.json.zst` |
|        | Renewal |  `https://data.nextstrain.org/files/workflows/forecasts-ncov/usa/renewal/<YYYY-MM-DD>_results.json.zst` |

## Installation

Please follow [installation instructions](https://docs.nextstrain.org/en/latest/install.html#installation-steps) for Nextstrain's software tools.

## Usage

To run pipeline for all available data for generated by ingest:

```
nextstrain build .
```

To run the pipeline for specific data provenance and geo resolution (e.g. gisaid and global only):

```
nextstrain build . --configfile config/config.yaml --config data_provenances=gisaid geo_resolutions=global
```

### Optional uploads

To run the pipeline that uploads the model results to S3 and sends Slack notifications:

```
nextstrain build . --configfile config/config.yaml config/optional.yaml
```

OR

Run the GitHub Action workflow named "Run models" to run the pipeline on AWS Batch.


## Configuration
The `data_provenances` and `geo_resolutions` are required configs for the pipeline.

The current available options for `data_provenances` are
- open
- gisaid

The current available options for `geo_resolutions` are
- global
- usa

Edit the `prepare_data` params in `config/config.yaml` if you want to change any data preparation options.

### Model configurations
The specific model configurations are housed in separate config YAML files or each model.
These separate config files must be provided in the main config as `mlr_config` and `renewal_config` in order to run the models.
By default, the model config files used are `config/mlr-config.yaml` and `config/renewal-config.yaml`.
Note the inputs and outputs for the models are overridden in the Snakemake pipeline to conform to the Snakemake input/output framework.

### Environment variables

No environment variables are required for open data.
However, the following environment variables are required for the gisaid data:
- `AWS_DEFAULT_REGION`
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`

#### Uploads
If running pipeline with uploads to S3, the following environment variables are required (regardless of data provenance):
- `AWS_DEFAULT_REGION`
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`

#### Slack notifications
If running pipeline with Slack notifications, the following environment variables are required:
- `SLACK_CHANNELS`
- `SLACK_TOKEN`

[nextstrain/ncov-ingest]: https://github.com/nextstrain/ncov-ingest
